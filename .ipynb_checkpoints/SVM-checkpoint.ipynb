{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, lfilter\n",
    "import math\n",
    "from scipy import stats\n",
    "import csv\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset\n",
    "mat = scipy.io.loadmat('SSVEPDataset.mat')\n",
    "data = mat['subject'][0]\n",
    "number_of_subjects = len(data)\n",
    "number_of_conditions = len(data[0])\n",
    "number_of_samplings = len(data[0][0])\n",
    "print \"Data includes\", number_of_subjects, \"subjects :\"\n",
    "print \"(\", number_of_conditions, \"conditions per subject )\"\n",
    "print \"(\", number_of_samplings, \"samplings per condition )\"\n",
    "#print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, condition_id):\n",
    "\n",
    "    #get data\n",
    "    data_selected = np.zeros((number_of_subjects, number_of_samplings-number_of_filter_out_samplings))\n",
    "    for i, d in enumerate(data):\n",
    "        #one loop is one subject\n",
    "        join_list = list(itertools.chain.from_iterable(d[condition_id-1]))\n",
    "\n",
    "        #bandpass filter\n",
    "        nyq = 0.5 * number_of_samplings_per_sec\n",
    "        low = 7 / nyq\n",
    "        high = 8 / nyq\n",
    "        order = 2\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        f = lfilter(b, a, join_list)\n",
    "\n",
    "        #filter out first-nine second\n",
    "        data_selected[i] = f[number_of_filter_out_samplings:]\n",
    "\n",
    "    print \"Select data from condition #\", condition_id\n",
    "    print \"Size of data is\", len(data_selected), \"subjects with\", len(data_selected[0]), \"samplings per subject.\"\n",
    "    \n",
    "    return data_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_fft(data_selected):\n",
    "\n",
    "    #FFT\n",
    "    for i, d in enumerate(data_selected):\n",
    "        print \"==== FFT with subjects #\", i, \"====\"\n",
    "        for index in range(0, number_of_slide_windows):\n",
    "            #one loop per window\n",
    "#             print \"From second #\", index, \"to\", index+window_size-1,\"( sampling no.\", \\\n",
    "#                     index*number_of_samplings_per_sec, \"to\", (index + window_size) * number_of_samplings_per_sec - 1, \")\"\n",
    "\n",
    "            #FFT\n",
    "            fft_out = fft(d[index*number_of_samplings_per_sec : (index + window_size) * number_of_samplings_per_sec])\n",
    "\n",
    "            freqs = fftfreq(len(fft_out)) * number_of_samplings_per_sec\n",
    "\n",
    "            #Get maximum magnitude value from window_size freq\n",
    "            if window_size == 5:\n",
    "                fix_freq = 7.6\n",
    "            elif window_size == 6:\n",
    "                fix_freq = 7.5\n",
    "            elif window_size == 8:\n",
    "                #still cannot find fix freq\n",
    "                #peak is around 7.56-7.58\n",
    "                #but after find from 7.5 to 7.8 (with scale + 0.00001), I still cannot find it\n",
    "                fix_freq = 7.5\n",
    "            elif window_size == 10:\n",
    "                fix_freq = 7.6\n",
    "\n",
    "            fft_out_max_list[i][index] = np.abs(fft_out)[np.where(freqs==fix_freq)]\n",
    "\n",
    "            if index == number_of_slide_windows - 1:\n",
    "                #plot FFT of some specific window\n",
    "                fig, ax = plt.subplots()\n",
    "                ax.plot(freqs, np.abs(fft_out))\n",
    "                ax.set_xlabel('Frequency in Hertz [Hz]')\n",
    "                ax.set_ylabel('Frequency Domain (Spectrum) Magnitude')\n",
    "                ax.set_xlim(1, 15)\n",
    "                ax.set_ylim(1, 2500)\n",
    "                plt.grid()\n",
    "                plt.show() \n",
    "\n",
    "        #z-score normalization\n",
    "        fft_out_max_list[i] = stats.zscore(fft_out_max_list[i])  \n",
    "\n",
    "        plt.plot(fft_out_max_list[i], 'ro')\n",
    "        plt.xlabel('Window no.')\n",
    "        plt.ylabel('Max Spectrum Magnitude')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "    return fft_out_max_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_curve(x, y, degree):\n",
    "    coefs = []\n",
    "    \n",
    "    if len(x) == len(y[0]):\n",
    "        for i in range(number_of_subjects):\n",
    "            coefs.append(np.polyfit(x, y[i], degree))\n",
    "    else:\n",
    "        for i in range(number_of_subjects):\n",
    "            coefs.append(np.polyfit(x[i], y[i], degree))\n",
    "        \n",
    "    print 'Curve fitting done!'\n",
    "    return coefs   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_div(x, coef):\n",
    "    ffit = np.poly1d(coef)\n",
    "    div = ffit.deriv()\n",
    "    return div(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(coef):\n",
    "    features = np.zeros(shape = (number_of_subjects,number_of_selected_windows))\n",
    "    for i in range(number_of_subjects):\n",
    "        #print 'subject', i\n",
    "        for j in range(number_of_selected_windows):\n",
    "            #print 'feature#', j, get_div(j+1, coef[i])\n",
    "            features[i][j] = get_div(j+1, coef[i])\n",
    "    print 'get', len(features[0]),'features per each subject in this condition.'\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(coef, fft_out, cond):\n",
    "    for i, c in enumerate(coef):\n",
    "        ffit = np.poly1d(c)\n",
    "        ys = []\n",
    "        for x in range(1,number_of_slide_windows+1):\n",
    "            ys.append(ffit(x))\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        ax1.scatter( range(1,number_of_slide_windows+1), ys, s=10, c='b', marker=\"s\", label='curve fitting')\n",
    "        ax1.scatter( range(1,number_of_slide_windows+1), fft_out[i], s=10, c='r', marker=\"o\", label='actual data')\n",
    "        plt.title('Subject#' + str(i) + ', Condition#' + str(cond))\n",
    "        plt.legend(loc='upper left');\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(features):\n",
    "    transformed_x = np.zeros(shape = (number_of_subjects*number_of_selected_conditions, number_of_selected_windows))\n",
    "    y = np.empty(shape = (number_of_subjects*number_of_selected_conditions,1))\n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        #print 'condition', i\n",
    "        for j in range(len(features[i])):\n",
    "            #print 'subject', j, 'index', number_of_subjects*i + j, 'feature', features[i][j]\n",
    "            transformed_x[number_of_subjects*i + j] = features[i][j]\n",
    "            y[number_of_subjects*i + j] = i\n",
    "    \n",
    "    return transformed_x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x, y, test_size = 1, r=0):\n",
    "\n",
    "    print \"Subject #\", r, \"is test set.\"\n",
    "    print 'test :', r, r + number_of_subjects, r + number_of_subjects*2\n",
    "    \n",
    "    x_tr = np.zeros(shape = ((number_of_subjects-test_size)*number_of_selected_conditions, number_of_selected_windows))\n",
    "    y_tr = np.zeros(shape = ((number_of_subjects-test_size)*number_of_selected_conditions, 1))\n",
    "    x_te = np.zeros(shape = (number_of_selected_conditions, number_of_selected_windows))\n",
    "    y_te = np.zeros(shape = (number_of_selected_conditions, 1))\n",
    "    \n",
    "    cnt_tr = 0\n",
    "    cnt_te = 0\n",
    "    for i in range(len(x)):\n",
    "        if i in [r, r + number_of_subjects, r + number_of_subjects*2]:\n",
    "            x_te[cnt_te] = x[i]\n",
    "            y_te[cnt_te] = y[i]\n",
    "            cnt_te += 1\n",
    "        else:\n",
    "            x_tr[cnt_tr] = x[i]\n",
    "            y_tr[cnt_tr] = y[i]\n",
    "            cnt_tr += 1\n",
    "    \n",
    "    y_tr = y_tr.reshape(1, -1)[0]\n",
    "    y_te = y_te.reshape(1, -1)[0]\n",
    "    \n",
    "    return x_tr, \\\n",
    "            x_te, \\\n",
    "            y_tr, \\\n",
    "            y_te, \\\n",
    "            r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## perform SVM\n",
    "#setting parameters\n",
    "number_of_cv_rounds = number_of_subjects\n",
    "test_size = 1\n",
    "\n",
    "all_correct = 0\n",
    "all_incorrect = 0\n",
    "x, y = transform_features(features)\n",
    "for i in range(0, number_of_cv_rounds):\n",
    "    X_train, X_test, y_train, y_test, subject_id = train_test_split(x = x, y = y, \\\n",
    "                                                            test_size=test_size, r = i)\n",
    "    print 'y_test', y_test\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for y_t, y_p in itertools.izip(y_test, y_pred):\n",
    "        if y_t == np.argmax(y_p):\n",
    "            correct = correct+1\n",
    "            all_correct = all_correct+1\n",
    "        else:\n",
    "            incorrect = incorrect+1\n",
    "            all_incorrect = all_incorrect+1\n",
    "            \n",
    "    print 'y_pred', y_pred\n",
    "    print 'correct:', correct\n",
    "    print 'incorrect:', incorrect\n",
    "    print\n",
    "    \n",
    "print 'All correct:', all_correct\n",
    "print 'All incorrect:', all_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform SVM\n",
    "#setting parameters\n",
    "number_of_cv_rounds = number_of_subjects\n",
    "test_size = 1\n",
    "\n",
    "all_correct = 0\n",
    "all_incorrect = 0\n",
    "x, y = transform_features(features)\n",
    "for i in range(0, number_of_cv_rounds):\n",
    "    X_train, X_test, y_train, y_test, subject_id = train_test_split(x = x, y = y, \\\n",
    "                                                            test_size=test_size, r = i)\n",
    "    print 'y_test', y_test\n",
    "    clf = svm.LinearSVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for y_t, y_p in itertools.izip(y_test, y_pred):\n",
    "        if y_t == np.argmax(y_p):\n",
    "            correct = correct+1\n",
    "            all_correct = all_correct+1\n",
    "        else:\n",
    "            incorrect = incorrect+1\n",
    "            all_incorrect = all_incorrect+1\n",
    "            \n",
    "    print 'y_pred', y_pred\n",
    "    print 'correct:', correct\n",
    "    print 'incorrect:', incorrect\n",
    "    print\n",
    "    \n",
    "print 'All correct:', all_correct\n",
    "print 'All incorrect:', all_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
