{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, lfilter\n",
    "from random import randint\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.preprocessing as prep\n",
    "import math\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy import stats\n",
    "import csv\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dataset\n",
    "mat = scipy.io.loadmat('SSVEPDataset.mat')\n",
    "data = mat['subject'][0]\n",
    "number_of_subjects = len(data)\n",
    "number_of_conditions = len(data[0])\n",
    "number_of_samplings = len(data[0][0])\n",
    "print \"Data includes\", number_of_subjects, \"subjects :\"\n",
    "print \"(\", number_of_conditions, \"conditions per subject )\"\n",
    "print \"(\", number_of_samplings, \"samplings per condition )\"\n",
    "#print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select one condition data and filter out first 10-second data\n",
    "#set params\n",
    "condition_id = 3 # ( 1 to 5 )\n",
    "number_of_samplings_per_sec = 250\n",
    "filtered_secs = 9\n",
    "all_secs = number_of_samplings/number_of_samplings_per_sec\n",
    "used_secs = all_secs - filtered_secs\n",
    "number_of_filter_out_samplings = number_of_samplings_per_sec * filtered_secs\n",
    "print \"Parameter setting : all =\", all_secs, \"seconds, used = \", used_secs, \"seconds\" \n",
    "\n",
    "#get data\n",
    "data_selected = np.zeros((number_of_subjects, number_of_samplings-number_of_filter_out_samplings))\n",
    "for i, d in enumerate(data):\n",
    "    #one loop is one subject\n",
    "    join_list = list(itertools.chain.from_iterable(d[condition_id-1]))\n",
    "    \n",
    "    #bandpass filter\n",
    "    nyq = 0.5 * number_of_samplings_per_sec\n",
    "    low = 7 / nyq\n",
    "    high = 8 / nyq\n",
    "    order = 2\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    f = lfilter(b, a, join_list)\n",
    "    \n",
    "    #filter out first-nine second\n",
    "    data_selected[i] = f[number_of_filter_out_samplings:]\n",
    "\n",
    "print \"Select data from condition #\", condition_id\n",
    "print \"Size of data is\", len(data_selected), \"subjects with\", len(data_selected[0]), \"samplings per subject.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform Fast Fourier Transform (FFT)\n",
    "#set params\n",
    "window_size = 5 #seconds\n",
    "number_of_slide_windows = used_secs-window_size+1\n",
    "fft_out_max_list = np.zeros((number_of_subjects, number_of_slide_windows))\n",
    "print \"Each subjects contains\", number_of_slide_windows, \"windows.\"\n",
    "\n",
    "#FFT\n",
    "for i, d in enumerate(data_selected):\n",
    "    print \"==== FFT with subjects #\", i, \"====\"\n",
    "    for index in range(0, number_of_slide_windows):\n",
    "        #one loop per window\n",
    "#         print \"From second #\", index, \"to\", index+window_size-1,\"( sampling no.\", index*number_of_samplings_per_sec, \"to\", (index + window_size) * number_of_samplings_per_sec - 1, \")\"\n",
    "        \n",
    "        #FFT\n",
    "        fft_out = fft(d[index*number_of_samplings_per_sec : (index + window_size) * number_of_samplings_per_sec])\n",
    "        \n",
    "        #z-score normalization\n",
    "        #fft_out = stats.zscore(fft_out)\n",
    "        \n",
    "        \"\"\"\n",
    "        #manual normalization (results are equal to above)\n",
    "        mean = np.mean(fft_out)\n",
    "        std = np.std(fft_out)\n",
    "        fft_out = [ (f-mean)/std for f in fft_out ]\n",
    "        \"\"\"\n",
    "        \n",
    "        freqs = fftfreq(len(fft_out)) * number_of_samplings_per_sec\n",
    "        \n",
    "        #Get maximum magnitude value from window_size freq\n",
    "        if window_size == 4:\n",
    "            fix_freq = 7.5\n",
    "        elif window_size == 5:\n",
    "            fix_freq = 7.6\n",
    "        elif window_size == 6:\n",
    "            fix_freq = 7.5\n",
    "        elif window_size == 8:\n",
    "            #still cannot find fix freq\n",
    "            #peak is around 7.56-7.58\n",
    "            #but after find from 7.5 to 7.8 (with scale + 0.00001), I still cannot find it\n",
    "            fix_freq = 7.5\n",
    "        elif window_size == 10:\n",
    "            fix_freq = 7.6\n",
    "\n",
    "        fft_out_max_list[i][index] = np.abs(fft_out)[np.where(freqs==fix_freq)]\n",
    "        \n",
    "        \"\"\" \n",
    "        if index == number_of_slide_windows - 1:\n",
    "            #plot FFT of some specific window\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(freqs, np.abs(fft_out))\n",
    "            ax.set_xlabel('Frequency in Hertz [Hz]')\n",
    "            ax.set_ylabel('Frequency Domain (Spectrum) Magnitude')\n",
    "            ax.set_xlim(1, 10)\n",
    "            ax.set_ylim(1, 40)\n",
    "            plt.grid()\n",
    "            plt.show() \n",
    "        \"\"\"\n",
    "            \n",
    "    #z-score normalization\n",
    "    fft_out_max_list[i] = stats.zscore(fft_out_max_list[i])   \n",
    "    \n",
    "        \n",
    "    plt.plot(fft_out_max_list[i], 'ro')\n",
    "    plt.xlabel('Window no.')\n",
    "    plt.ylabel('Max Spectrum Magnitude')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_result_to_csv(filename, results):\n",
    "    print 'Start writing results from', len(results[0]), 'subjects'\n",
    "    csvfile1 = open(filename + '_RMSE.csv', 'wb')\n",
    "    csvfile2 = open(filename + '_testscore.csv', 'wb')\n",
    "    \n",
    "    wr1 = csv.writer(csvfile1, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    wr2 = csv.writer(csvfile2, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "    wr1.writerow(['subject_id', 'RMSE_'+str(reduce_result_proportion[0]*100)+'%', \\\n",
    "                  'RMSE_'+str(reduce_result_proportion[1]*100)+'%', \\\n",
    "                  'RMSE_'+str(reduce_result_proportion[2]*100)+'%'])\n",
    "    wr2.writerow(['subject_id', 'testscore_'+str(reduce_result_proportion[0]*100)+'%', \\\n",
    "              'testscore_'+str(reduce_result_proportion[1]*100)+'%', \\\n",
    "              'testscore_'+str(reduce_result_proportion[2]*100)+'%'])\n",
    "    \n",
    "    for i in range(0, number_of_subjects):\n",
    "        wr1.writerow([i, results[0][i]['RMSE'], results[1][i]['RMSE'], \\\n",
    "                      results[2][i]['RMSE']])\n",
    "        wr2.writerow([i, results[0][i]['test_score'], results[1][i]['test_score'], \\\n",
    "                      results[2][i]['test_score']])\n",
    "    \n",
    "    csvfile1.close()\n",
    "    csvfile2.close()\n",
    "    \n",
    "    print 'Finish writing :', filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x, y, test_size = 1, fix_subject = None):\n",
    "    \n",
    "    r = []\n",
    "    if fix_subject == None:\n",
    "        while True:\n",
    "            status = False\n",
    "            for i in range(test_size):\n",
    "                rand = 0\n",
    "                while True:\n",
    "                    rand = randint(0, number_of_subjects-1)\n",
    "                    if rand not in r:\n",
    "                        break\n",
    "                    else:\n",
    "                        print rand, r\n",
    "                r.append(rand)\n",
    "\n",
    "            for ri in rand_indices:\n",
    "                if set(ri) == set(r):\n",
    "                    r = []\n",
    "                    status = True\n",
    "                    break\n",
    "\n",
    "            if not status:\n",
    "                break\n",
    "    else:\n",
    "        r = [fix_subject]\n",
    "            \n",
    "            \n",
    "    print \"Random result: subject #\", r, \"is test set.\"\n",
    "    rand_indices.append(r)\n",
    "    \n",
    "    x_test = np.array([x[i] for i in r]).reshape(-1,1)\n",
    "    x_train = np.array([x[i] for i in range(number_of_subjects) if i not in r]).reshape(-1,1)\n",
    "    y_test = y[1:test_size+1]\n",
    "    y_test = np.concatenate(y_test)\n",
    "    y_train = y[1:number_of_subjects-test_size+1]\n",
    "    y_train = np.concatenate(y_train)\n",
    "    \n",
    "    return x_train, \\\n",
    "            x_test, \\\n",
    "            y_train, \\\n",
    "            y_test, \\\n",
    "            r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Non-Linear Regression by me\n",
    "\n",
    "# set params\n",
    "test_set_fraction = 1.0/12\n",
    "test_size = 1\n",
    "rand_indices = []\n",
    "results = []\n",
    "number_of_cv_rounds = number_of_subjects\n",
    "\n",
    "\n",
    "# setting light intensity data\n",
    "if condition_id == 5:\n",
    "    first_light_intensity_begin = 150\n",
    "    last_light_intensity_begin = 255\n",
    "    light_intensity_up = np.arange(first_light_intensity_begin, last_light_intensity_begin, intensity_step)\n",
    "    light_intensity_down = np.arange(last_light_intensity_begin, first_light_intensity_begin, -(intensity_step))\n",
    "    light_intensity = np.concatenate([light_intensity_up, light_intensity_down])[0:number_of_slide_windows]\n",
    "    last_light_intensity_begin = light_intensity[len(light_intensity)-1]\n",
    "    light_intensity = np.tile(light_intensity,(number_of_subjects,1))\n",
    "else:\n",
    "    intensity_step = 3\n",
    "    first_light_intensity_begin = 75\n",
    "    last_light_intensity_begin = (number_of_slide_windows * intensity_step) + first_light_intensity_begin\n",
    "    light_intensity = np.arange(first_light_intensity_begin, last_light_intensity_begin, intensity_step)\n",
    "    light_intensity = np.tile(light_intensity,(number_of_subjects,1))\n",
    "\n",
    "\n",
    "print \"Parameter settings: 1st window start at intensity =\", first_light_intensity_begin, \\\n",
    "        \", end at intensity =\", last_light_intensity_begin, \\\n",
    "        \", cross validation =\", number_of_cv_rounds\n",
    "print\n",
    "\n",
    "selected_data_start = 14\n",
    "selected_data_end = 34\n",
    "\n",
    "## prepare list to store results\n",
    "results = []\n",
    "reduce_result_proportion = [1, 1, 1]\n",
    "filename = './results/train_21pts_con' + str(condition_id)\n",
    "\n",
    "for c, r in enumerate(reduce_result_proportion):\n",
    "    print '#### Begin calculate with result proportion =', r, '####'\n",
    "    results.append([])\n",
    "    \n",
    "    for i in range(0, number_of_cv_rounds):\n",
    "        X_train, X_test, y_train, y_test, subject_id = train_test_split(x = fft_out_max_list, y = light_intensity, \\\n",
    "                                                                test_size=test_size, fix_subject = i)\n",
    "        \n",
    "        \n",
    "        print \"X_train :\", len(X_train), \", X_test :\", len(X_test), \", y_train :\", len(y_train), \", y_test :\", len(y_test)\n",
    "        print\n",
    "        \n",
    "#         X_train = X_train[:int(len(X_train)*r)]\n",
    "#         X_test = X_test[:int(len(X_test)*r)]\n",
    "#         y_train = y_train[:int(len(y_train)*r)]\n",
    "#         y_test = y_test[:int(len(y_test)*r)]\n",
    "\n",
    "        ## non-linear regression\n",
    "        model = prep.PolynomialFeatures(degree=3)\n",
    "        X_tr = model.fit_transform(X_train, y_train)\n",
    "        X_te = model.fit_transform(X_test)\n",
    "        \n",
    "#         X_tr = X_tr[selected_data_start:selected_data_end]\n",
    "#         y_train = y_train[selected_data_start:selected_data_end]\n",
    "#         X_te = X_te[selected_data_start:selected_data_end]\n",
    "#         y_test=y_test[selected_data_start:selected_data_end]   \n",
    "#         X_test=X_test[selected_data_start:selected_data_end]\n",
    "\n",
    "        clf = linear_model.LinearRegression()\n",
    "        clf.fit(X_tr, y_train)\n",
    "        y_pred = clf.predict(X_te)\n",
    "\n",
    "        # calculate Root Mean Square Error\n",
    "#         RMSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "        test_score = 1 - clf.score(X_te,y_test)\n",
    "        RMSE = np.sqrt(np.sum(np.square(y_pred-y_test))/ len(y_pred))\n",
    "        print \"Round :\", i, \", RMSE:\", RMSE, \", test_score:\", test_score\n",
    "        \n",
    "        #store results\n",
    "        results[c].append(dict({\n",
    "            'subject_id' : subject_id,\n",
    "            'RMSE' : RMSE,\n",
    "            'test_score' : test_score\n",
    "        }))\n",
    "\n",
    "        ## plot non-linear regression result\n",
    "        x = list(itertools.islice(itertools.count(), first_light_intensity_begin, last_light_intensity_begin, intensity_step))\n",
    "        x = x[:int(len(x)*r)]\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(111)\n",
    "\n",
    "        ax1.scatter(X_test, y_pred, s=10, c='b', marker=\"s\", label='pred')\n",
    "        ax1.scatter(X_test, y_test, s=10, c='r', marker=\"o\", label='actual')\n",
    "        plt.xlabel('Normalized SSVEP', fontsize=12, fontweight='bold')\n",
    "        plt.ylabel('Light Intensity', fontsize=12, fontweight='bold')\n",
    "#         ax.set_ylim(-1.75, 1.75)\n",
    "        #plt.show()\n",
    "        plt.savefig('./results/train_21pts_' + str(condition_id) + '_' + str(subject_id) + '.png')\n",
    "        plt.legend(loc='upper left');\n",
    "        plt.show()\n",
    "        \n",
    "    print 'Store results of', len(results[c]), 'subjects done!'\n",
    "    print\n",
    "    \n",
    "write_result_to_csv(filename, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Non-Linear Regression by Tutorial\n",
    "# # Alpha (regularization strength) of LASSO regression\n",
    "# lasso_eps = 0.001\n",
    "# lasso_nalpha=20\n",
    "# lasso_iter=1000\n",
    "\n",
    "# # set params\n",
    "# test_set_fraction = 1.0/12\n",
    "# test_size = 1\n",
    "# rand_indices = []\n",
    "# number_of_cv_rounds = number_of_subjects\n",
    "# intensity_step = 3\n",
    "# first_light_intensity_begin = 105\n",
    "# last_light_intensity_begin = (number_of_slide_windows * intensity_step) + first_light_intensity_begin\n",
    "# print \"Parameter settings: 1st window start at intensity =\", first_light_intensity_begin, \\\n",
    "#         \", end at intensity =\", last_light_intensity_begin, \\\n",
    "#         \", cross validation =\", number_of_cv_rounds\n",
    "# print\n",
    "\n",
    "# ## prepare list to store results\n",
    "# tutorial_results = []\n",
    "# reduce_result_proportion = [1, 0.5, 0.25]\n",
    "# filename = './tutorial_results'\n",
    "\n",
    "# # Test/train split\n",
    "# light_intensity = np.arange(first_light_intensity_begin, last_light_intensity_begin, intensity_step)\n",
    "# light_intensity = np.tile(light_intensity,(number_of_subjects,1))\n",
    "\n",
    "# for c, r in enumerate(reduce_result_proportion):\n",
    "#     print '#### Begin calculate with result proportion =', r, '####'\n",
    "#     tutorial_results.append([])\n",
    "    \n",
    "#     for i in range(0, number_of_cv_rounds):\n",
    "#         # Make a pipeline model with polynomial transformation and LASSO regression with cross-validation, \n",
    "#         # run it for increasing degree of polynomial (complexity of the model)\n",
    "\n",
    "#         model = make_pipeline(prep.PolynomialFeatures(degree=3, interaction_only=False), \\\n",
    "#                               linear_model.LassoCV(eps=lasso_eps,n_alphas=lasso_nalpha,max_iter=lasso_iter,\\\n",
    "#                                                    normalize=True,cv=number_of_cv_rounds))\n",
    "\n",
    "#         X_train, X_test, y_train, y_test, subject_id = train_test_split(x = light_intensity, y = fft_out_max_list, \\\n",
    "#                                                                         test_size=test_size, fix_subject = i)\n",
    "        \n",
    "#         X_train = X_train[:int(len(X_train)*r)]\n",
    "#         X_test = X_test[:int(len(X_test)*r)]\n",
    "#         y_train = y_train[:int(len(y_train)*r)]\n",
    "#         y_test = y_test[:int(len(y_test)*r)]\n",
    "        \n",
    "#         model.fit(X_train,y_train)\n",
    "#         y_pred = np.array(model.predict(X_test))\n",
    "#         RMSE = np.sqrt(np.sum(np.square(y_pred-y_test)) / len(y_pred))\n",
    "#         test_score = model.score(X_test,y_test)\n",
    "\n",
    "#         ## store results\n",
    "#         tutorial_results[c].append(dict({\n",
    "#             'subject_id' : subject_id,\n",
    "#             'RMSE' : RMSE,\n",
    "#             'test_score' : test_score\n",
    "#         }))\n",
    "\n",
    "#         ## plot non-linear regression result\n",
    "#         x = list(itertools.islice(itertools.count(), first_light_intensity_begin, last_light_intensity_begin, intensity_step))\n",
    "#         x = x[:int(len(x)*r)]\n",
    "#         fig = plt.figure()\n",
    "#         ax1 = fig.add_subplot(111)\n",
    "\n",
    "#         ax1.scatter(x, y_pred, s=10, c='b', marker=\"s\", label='pred')\n",
    "#         ax1.scatter(x, y_test, s=10, c='r', marker=\"o\", label='actual')\n",
    "#         plt.legend(loc='upper left');\n",
    "#         plt.show()\n",
    "\n",
    "#     print 'Store results of', len(tutorial_results[c]), 'subjects', len(x), 'points per subject done!'\n",
    "#     print\n",
    "    \n",
    "# write_result_to_csv(filename, tutorial_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## try linear regression (not be used)\n",
    "# model = linear_model.LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# #calculate Mean Square Error\n",
    "# mse = np.sum(abs(y_pred-y_test)) / len(y_test)\n",
    "\n",
    "# ## plot linear regression result (not be used)\n",
    "# x = list(itertools.islice(itertools.count(), first_light_intensity_begin, last_light_intensity_begin, intensity_step))\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(111)\n",
    "\n",
    "# ax1.scatter(x, y_pred, s=10, c='b', marker=\"s\", label='pred')\n",
    "# ax1.scatter(x, y_test, s=10, c='r', marker=\"o\", label='actual')\n",
    "# plt.legend(loc='upper left');\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
